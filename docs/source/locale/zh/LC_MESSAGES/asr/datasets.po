# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018-2020, NVIDIA
# This file is distributed under the same license as the nemo package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: nemo 0.10.0b10\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-04-02 10:41-0700\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../asr/datasets.rst:2
msgid "Datasets"
msgstr ""

#: ../../asr/datasets.rst:7
msgid "LibriSpeech"
msgstr ""

#: ../../asr/datasets.rst:9
msgid ""
"Run these scripts to download LibriSpeech data and convert it into format"
" expected by `nemo_asr`. You should have at least 250GB free space."
msgstr ""

#: ../../asr/datasets.rst:19
msgid ""
"After this, your `data` folder should contain wav files and `.json` "
"manifests for NeMo ASR datalayer:"
msgstr ""

#: ../../asr/datasets.rst:22
msgid ""
"Each line is a training example. `audio_filepath` contains path to the "
"wav file, `duration` it's duration in seconds and `text` it's transcript:"
msgstr ""

#: ../../asr/datasets.rst:30
msgid "Fisher English Training Speech"
msgstr ""

#: ../../asr/datasets.rst:32
msgid ""
"Run these scripts to convert the Fisher English Training Speech data into"
" a format expected by the `nemo_asr` collection."
msgstr ""

#: ../../asr/datasets.rst:34
msgid ""
"In brief, the following scripts convert the .sph files to .wav, slice "
"those files into smaller audio samples, match the smaller slices with "
"their corresponding transcripts, and split the resulting audio segments "
"into train, validation, and test sets (with one manifest each)."
msgstr ""

#: ../../asr/datasets.rst:37
msgid ""
"You will need at least 106GB of space to run the .wav conversion, and an "
"additional 105GB for the slicing and matching. You will need to have "
"sph2pipe installed in order to run the .wav conversion."
msgstr ""

#: ../../asr/datasets.rst:41
msgid "**Instructions**"
msgstr ""

#: ../../asr/datasets.rst:43
msgid ""
"These scripts assume that you already have the Fisher dataset from the "
"Linguistic Data Consortium, with a directory structure that looks "
"something like this:"
msgstr ""

#: ../../asr/datasets.rst:61
msgid ""
"The transcripts that will be used are located in "
"`fe_03_p<1,2>_transcripts/data/trans`, and the audio files (.sph) are "
"located in the remaining directories in an `audio` subdirectory."
msgstr ""

#: ../../asr/datasets.rst:63
msgid "First, convert the audio files from .sph to .wav by running:"
msgstr ""

#: ../../asr/datasets.rst:71
msgid ""
"This will place the unsliced .wav files in "
"`<conversion_target_dir>/LDC200[4,5]S13-Part[1,2]/audio-wav/`. It will "
"take several minutes to run."
msgstr ""

#: ../../asr/datasets.rst:74
msgid "Next, process the transcripts and slice the audio data:"
msgstr ""

#: ../../asr/datasets.rst:83
msgid ""
"This script will split the full dataset into train, validation, and test "
"sets, and place the audio slices in the corresponding folders in the "
"destination directory. One manifest will be written out per set, which "
"includes each slice's transcript, duration, and path."
msgstr ""

#: ../../asr/datasets.rst:86
msgid ""
"This will likely take around 20 minutes to run. Once finished, you may "
"delete the 10 minute long .wav files if you wish."
msgstr ""

#: ../../asr/datasets.rst:90
msgid "2000 HUB5 English Evaluation Speech"
msgstr ""

#: ../../asr/datasets.rst:92
msgid ""
"Run the following script to convert the HUB5 data into a format expected "
"by the `nemo_asr` collection."
msgstr ""

#: ../../asr/datasets.rst:94
msgid ""
"Similarly to the Fisher dataset processing scripts, this script converts "
"the .sph files to .wav, slices the audio files and transcripts into "
"utterances, and combines them into segments of some minimum length "
"(default is 10 seconds). The resulting segments are all written out to an"
" audio directory, and the corresponding transcripts are written to a "
"manifest JSON file."
msgstr ""

#: ../../asr/datasets.rst:98
msgid ""
"You will need 5GB of free space to run this script. You will also need to"
" have sph2pipe installed."
msgstr ""

#: ../../asr/datasets.rst:101
msgid ""
"This script assumes you already have the 2000 HUB5 dataset from the "
"Linguistic Data Consortium."
msgstr ""

#: ../../asr/datasets.rst:103
msgid ""
"Run the following to process the 2000 HUB5 English Evaluation Speech "
"samples:"
msgstr ""

#: ../../asr/datasets.rst:111
msgid ""
"You may optionally include `--min_slice_duration=<num_seconds>` if you "
"would like to change the minimum audio segment duration."
msgstr ""

#: ../../asr/datasets.rst:114
msgid "AN4 Dataset"
msgstr ""

#: ../../asr/datasets.rst:116
msgid ""
"This is a small dataset recorded and distributed by Carnegie Mellon "
"University, and consists of recordings of people spelling out addresses, "
"names, etc. Information about this dataset can be found on the `official "
"CMU site <http://www.speech.cs.cmu.edu/databases/an4/>`_."
msgstr ""

#: ../../asr/datasets.rst:119
msgid ""
"Please download and extract the dataset (which is labeled \"NIST's Sphere"
" audio (.sph) format (64M)\" on the site linked above): "
"http://www.speech.cs.cmu.edu/databases/an4/an4_sphere.tar.gz."
msgstr ""

#: ../../asr/datasets.rst:121
msgid ""
"Running the following script will convert the .sph files to .wav using "
"sox, and build one training and one test manifest."
msgstr ""

#: ../../asr/datasets.rst:127
msgid ""
"Once this script finishes, you should have a `train_manifest.json` and "
"`test_manifest.json` in the `<data_root>/an4/` directory."
msgstr ""

#: ../../asr/datasets.rst:130
msgid "Aishell1"
msgstr ""

#: ../../asr/datasets.rst:132
msgid ""
"Run these scripts to download Aishell1 data and convert it into format "
"expected by `nemo_asr`."
msgstr ""

#: ../../asr/datasets.rst:141
msgid ""
"After this, your `data` folder should contain a `data_aishell` folder "
"which contains wav, transcript folder and related `.json` files and "
"`vocab.txt`."
msgstr ""

#: ../../asr/datasets.rst:144
msgid "Aishell2"
msgstr ""

#: ../../asr/datasets.rst:146
msgid ""
"Run the script to process AIShell-2 dataset in order to generate files in"
" the supported format of  `nemo_asr`. You should set the data folder of "
"AIShell-2 using `--audio_folder` and where to push these files using "
"`--dest_folder`."
msgstr ""

#: ../../asr/datasets.rst:152
msgid ""
"Then, you should have `train.json` `dev.json` `test.json` and `vocab.txt`"
" in `dest_folder`."
msgstr ""

