# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018-2020, NVIDIA
# This file is distributed under the same license as the nemo package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: nemo 0.10.0b10\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-04-02 10:41-0700\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../speech_command/datasets.rst:2
msgid "Datasets"
msgstr ""

#: ../../speech_command/datasets.rst:8
msgid "Google Speech Commands Dataset"
msgstr ""

#: ../../speech_command/datasets.rst:10
msgid ""
"The ability to recognize spoken commands with high accuracy can be useful"
" in a variety of contexts. To this end, Google released the Speech "
"Commands dataset (see :cite:`speech-recognition-dataset-"
"warden2018speech`, which contains short audio clips of a fixed number of "
"command words such as “stop”, “go”, “up”, “down”, etc spoken by a large "
"number of speakers. To promote the use of the set, Google also hosted a "
"Kaggle competition, in which the winning team attained a multi-class "
"accuracy of 91%."
msgstr ""

#: ../../speech_command/datasets.rst:15
msgid ""
"We experimented with applying NeMo’s ASR classification models on mel "
"spectrogram of the audio clips and found that they worked surprisingly "
"well. Adding data augmentation further improved the results."
msgstr ""

#: ../../speech_command/datasets.rst:19
msgid "Dataset"
msgstr ""

#: ../../speech_command/datasets.rst:21
msgid ""
"Google released two versions of the dataset with the first version "
"containing 65k samples over 30 classes and the second containing 110k "
"samples over 35 classes. We refer to these datasets as v1 and v2, and "
"currently we have metrics for v1 version in order to compare to the "
"different metrics used by other papers."
msgstr ""

#: ../../speech_command/datasets.rst:24
msgid ""
"Run the script `process_speech_commands_data.py` to process Google Speech"
" Commands dataset in order to generate files in the supported format of  "
"`nemo_asr`, which can be found in the `scripts` sub-directory of the nemo"
" base directory. You should set the data folder of Speech Commands using "
"`--data_root` and the version of the dataset using `--data_version` as an"
" int."
msgstr ""

#: ../../speech_command/datasets.rst:27
msgid "You can further rebalance the train set by passing the `--rebalance` flag."
msgstr ""

#: ../../speech_command/datasets.rst:33
msgid ""
"Then, you should have `train_manifest.json`, `validation_manifest.json` "
"and `test_manifest.json` in the directory "
"`{data_root}/google_speech_recognition_v{1/2}`."
msgstr ""

#: ../../speech_command/datasets.rst:37
msgid "References"
msgstr ""

