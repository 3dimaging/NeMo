# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018-2020, NVIDIA
# This file is distributed under the same license as the nemo package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: nemo 0.10.0b10\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-04-02 10:41-0700\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../tutorials/custommodules.rst:2
msgid "How to build Neural Module"
msgstr ""

#: ../../tutorials/custommodules.rst:5
msgid "Currently, NeMo only supports PyTorch as a backend."
msgstr ""

#: ../../tutorials/custommodules.rst:7
msgid ""
"Neural Modules can be conceptually classified into 4 potentially "
"overlapping categories:"
msgstr ""

#: ../../tutorials/custommodules.rst:9
msgid ""
"**Trainable Modules** - modules that contain trainable weights. Inherit "
"from :class:`TrainableNM<nemo.backends.pytorch.nm.TrainableNM>` class."
msgstr ""

#: ../../tutorials/custommodules.rst:11
msgid ""
"**Data Layers** - modules that perform (extract, transform, load, feed) "
"ETLF of the data. Inherit from "
":class:`DataLayerNM<nemo.backends.pytorch.nm.DataLayerNM>` class."
msgstr ""

#: ../../tutorials/custommodules.rst:13
msgid ""
"**Loss Modules** - modules that compute loss functions. Inherit from "
":class:`LossNM<nemo.backends.pytorch.nm.LossNM>` class."
msgstr ""

#: ../../tutorials/custommodules.rst:15
msgid ""
"**Non Trainable Modules** - non-trainable module, for example, table "
"lookup, data augmentation, greedy decoder, etc. Inherit from "
":class:`NonTrainableNM<nemo.backends.pytorch.nm.NonTrainableNM>` class."
msgstr ""

#: ../../tutorials/custommodules.rst:18
msgid ""
"In the figure below you can see a class inheritance diagram for these "
"helper classes."
msgstr ""

#: ../../tutorials/custommodules.rst:23
msgid ""
"Inheritance class diagram. Provided API's classes are in green. Red "
"classes are to be implemented by user."
msgstr ""

#: ../../tutorials/custommodules.rst:26
msgid "Trainable Module"
msgstr ""

#: ../../tutorials/custommodules.rst:28
msgid ""
"Notice that :class:`TrainableNM<nemo.backends.pytorch.nm.TrainableNM>` "
"class has two base classes: "
":class:`NeuralModule<nemo.core.neural_modules.NeuralModule>` class and "
"``torch.nn.Module``."
msgstr ""

#: ../../tutorials/custommodules.rst:32
msgid "Defining a module from scratch"
msgstr ""

#: ../../tutorials/custommodules.rst:34
msgid ""
"Inherit from :class:`TrainableNM<nemo.backends.pytorch.nm.TrainableNM>` "
"class."
msgstr ""

#: ../../tutorials/custommodules.rst:35
msgid ""
"Create the ``input_ports`` and ``output_ports`` properties that define "
"your input and output ports."
msgstr ""

#: ../../tutorials/custommodules.rst:47
msgid "In the constructor, call base class constructor first"
msgstr ""

#: ../../tutorials/custommodules.rst:54
msgid "Implement ``forward`` method from ``torch.nn.Module``"
msgstr ""

#: ../../tutorials/custommodules.rst:57
msgid ""
"Input argument names to your ``forward`` method must match your module's "
"input port names exactly."
msgstr ""

#: ../../tutorials/custommodules.rst:60
msgid "Example 1"
msgstr ""

#: ../../tutorials/custommodules.rst:102
msgid "Converting from PyTorch's nn.Module"
msgstr ""

#: ../../tutorials/custommodules.rst:104
msgid ""
"If you already have a PyTorch class which inherits from "
"``torch.nn.Module``, replace that inheritance with inheritance from "
":class:`TrainableNM<nemo.backends.pytorch.nm.TrainableNM>` class."
msgstr ""

#: ../../tutorials/custommodules.rst:106
msgid "Implement the ``input_ports`` and ``output_ports`` properties"
msgstr ""

#: ../../tutorials/custommodules.rst:107
msgid "Modify your constructor to call the base class constructor first."
msgstr ""

#: ../../tutorials/custommodules.rst:122
msgid ""
"Modify ``forward`` method so that its input arguments match your input "
"port names exactly."
msgstr ""

#: ../../tutorials/custommodules.rst:125
msgid "Data Layer Module"
msgstr ""

#: ../../tutorials/custommodules.rst:126
msgid ""
"Inherit from :class:`DataLayerNM<nemo.backends.pytorch.nm.DataLayerNM>` "
"class."
msgstr ""

#: ../../tutorials/custommodules.rst:127
msgid "Implement ``__len__`` method to return dataset size."
msgstr ""

#: ../../tutorials/custommodules.rst:128
msgid ""
"Implement either the ``dataset`` or ``data_iterator`` property to return "
"a PyTorch Dataset object or an iterator over your dataset, respectively. "
"(The unused property should return None.)"
msgstr ""

#: ../../tutorials/custommodules.rst:130
msgid ""
"When implementing the constructor, you should first call the base class "
"constructor and define *output ports only* in ``output_ports``.  Also, "
"module should accept parameters such as ``batch_size`` and ``shuffle``."
msgstr ""

#: ../../tutorials/custommodules.rst:134
msgid ""
"If you are using ``torch.utils.data.Dataset`` class (*recommended "
"approach*), then you can implement the ``dataset`` property, and a "
"DataLoader will be created for you. Here is an example:"
msgstr ""

#: ../../tutorials/custommodules.rst:138 ../../tutorials/custommodules.rst:206
msgid "Example"
msgstr ""

#: ../../tutorials/custommodules.rst:140
msgid ""
"This example wraps PyTorch's *ImageFolder* dataset into a neural module "
"data layer."
msgstr ""

#: ../../tutorials/custommodules.rst:197
msgid "Loss Neural Module"
msgstr ""

#: ../../tutorials/custommodules.rst:199
msgid "Inherit from :class:`LossNM<nemo.backends.pytorch.nm.LossNM>` class"
msgstr ""

#: ../../tutorials/custommodules.rst:200
msgid "Create ports using the ``input_ports`` and ``output_ports`` properties"
msgstr ""

#: ../../tutorials/custommodules.rst:201
msgid "In your constructor, call base class constructor"
msgstr ""

#: ../../tutorials/custommodules.rst:202
msgid ""
"Implement "
":meth:`_loss_function<nemo.backends.pytorch.nm.LossNM._loss_function>` "
"method."
msgstr ""

