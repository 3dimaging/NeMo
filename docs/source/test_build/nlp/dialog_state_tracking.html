

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tutorial &mdash; nemo 0.10.0b0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorial" href="ner.html" />
    <link rel="prev" title="Transformer Language Model" href="transformer_language_model.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.10.0b0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Fast Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech_command/intro.html">Speech Commands</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="intro.html">Natural Language Processing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html#neural-machine-translation-nmt">Neural Machine Translation (NMT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#transformer-language-model">Transformer Language Model</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="intro.html#dialog-state-tracking">Dialog State Tracking</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-multiwoz-dataset">The MultiWOZ Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-trade-model">The TRADE model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-preprocessing">Data Preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#building-the-nemo-graph">Building the NeMo Graph</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#metrics-and-results">Metrics and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#punctuation-and-word-capitalization">Punctuation and Word Capitalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#intent-and-slot-filling">Intent and Slot filling</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#question-answering">Question Answering</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#improving-speech-recognition-with-bertx2-post-processing-model">Improving speech recognition with BERTx2 post-processing model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tts/intro.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chinese/intro.html">中文支持</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="intro.html">Natural Language Processing</a> &raquo;</li>
        
      <li>Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/nlp/dialog_state_tracking.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The goal of <strong>Dialog State Tracking (DST)</strong> <a class="bibtex reference internal" href="#nlp-dst-henderson2015machine" id="id1">[NLP-DST3]</a> is to build a representation of the status of the ongoing conversation being a sequence of utterances exchanged between dialog participants. In another words, the goal of DST system is to capture user goals and intentions and encode them as a set of <strong>slots</strong> along with the corresponding <strong>values</strong>.</p>
<div class="figure align-default" id="id13">
<img alt="../_images/dst_multi_woz_example.png" src="../_images/dst_multi_woz_example.png" />
<p class="caption"><span class="caption-text">Fig. 1: An exemplary, multi-domain dialog along with the associated state tracking (source: <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id2">[NLP-DST4]</a>)</span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
<p>In this tutorial we will focus on a multi-domain dialogue MultiWOZ dataset <a class="bibtex reference internal" href="#nlp-dst-budzianowski2018multiwoz" id="id3">[NLP-DST1]</a> and show how one can train a TRADE model <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id4">[NLP-DST4]</a>, being one of the recent, state of the art models. <strong>Multi-domain</strong> setting introduces several challanges, with the most important coming from the need for <strong>multi-turn mapping</strong>. In a <strong>single-turn mapping</strong> scenario the (<strong>domain</strong>, <strong>slot</strong>, <strong>value</strong>) triplet can be inferred from a single turn. In multi-turn this assumption does not hold and the DST system must infer those from multiple turns, possibly spanning over several different domains.</p>
</div>
<div class="section" id="the-multiwoz-dataset">
<h2>The MultiWOZ Dataset<a class="headerlink" href="#the-multiwoz-dataset" title="Permalink to this headline">¶</a></h2>
<p>The Multi-Domain Wizard-of-Oz dataset (<a class="reference external" href="https://www.repository.cam.ac.uk/handle/1810/294507">MultiWOZ</a>) is a collection of human-to-human conversations spanning over 7 distinct domains and containing over 10,000 dialogues.
The original MultiWOZ 2.0 dataset was introduced in <a class="bibtex reference internal" href="#nlp-dst-budzianowski2018multiwoz" id="id5">[NLP-DST1]</a>.
However, in this tutorial we will utilize MultiWOZ 2.1  <a class="bibtex reference internal" href="#nlp-dst-eric2019multiwoz" id="id6">[NLP-DST2]</a>, which aimed at fixing several issues with the original dataset (state errors and corrections, utterance corrections, value
cannonicalization etc.).</p>
<p>The MultiWOZ covers the following domains:
1. restaurant
2. hotel
3. attraction
4. taxi
5. train
6. hospital
7. police.</p>
<p>This division propagates further on the type of domain-specific actions:
* inform (∗)
* request (∗)
* select (123)
* recommend (123)
* not found (123)
* request booking info (123)
* offer booking (1235)
* inform booked (1235)
* decline booking (1235)
* welcome (∗)
* greet (∗)
* bye (∗)
* reqmore (∗).</p>
<p>As well as domain-specific slots:
* inform (∗)
* address (∗)
* postcode (∗)
* phone (∗)
* name (1234)
* no of choices (1235)
* area (123)
* pricerange (123)
* type (123)
* internet (2)
* parking (2)
* stars (2)
* open hours (3)
* departure (45)
* destination (45)
* leave after (45)
* arrive by (45)
* no of people (1235)
* reference no. (1235)
* trainID (5)
* ticket price (5)
* travel time (5)
* department (7)
* day (1235)
* no of days (123).</p>
<p>Please note that some of the actions and slots are associated with particular domain(s), whereas some are universal, i.e. domain independent. The latter ones are denoted with (∗).</p>
<p>MultiWOZ offers 10,438 dialogues, with 115,434 turns in total. Dialogues are generally classified into single and multi-domain dialogues. Dialogue length distribution is varying from 1 to 31, with around 70%of dialogues have more than 10 turns. The average number of turns are 8.93 and 15.39 for single and multi-domain dialogues. </p>
<p>Each dialogue consists of a goal, multiple user and system utterances as well as a belief state and set of dialogue acts with slots per turn. Additionally, each dialog is supported with a task description. Moreover, it contains both system and user dialogue act annotations (the latter introduced in MultiWOZ 2.1).</p>
</div>
<div class="section" id="the-trade-model">
<h2>The TRADE model<a class="headerlink" href="#the-trade-model" title="Permalink to this headline">¶</a></h2>
<p>The <strong>TRA</strong>nsferable <strong>D</strong>ialogue stat<strong>E</strong> generator  (TRADE)  is a model designed specially for the multi-domain task-oriented dialogue state tracking problem. The model generates dialogue states from utterances using a copy mechanism, what facilitates knowledge transfer between domains by predicting (<strong>domain</strong>, <strong>slot</strong>, <strong>value</strong>) triplets not encountered during training in a given domain.</p>
<div class="figure align-default" id="id14">
<img alt="../_images/dst_trade_model_architecture.png" src="../_images/dst_trade_model_architecture.png" />
<p class="caption"><span class="caption-text">Fig. 2: Architecture of the TRADE model (source: <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id7">[NLP-DST4]</a>)</span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</div>
<p>The model is composed of an three main components:</p>
<blockquote>
<div><ul class="simple">
<li><p>an <strong>utterance encoder</strong>,</p></li>
<li><p>a <strong>slot gate</strong>, and</p></li>
<li><p>a <strong>state generator</strong>.</p></li>
</ul>
</div></blockquote>
<p>The <strong>utterance encoder</strong> is a bi-directional Gated Recurrent Unit (GRU), returning both context words and and an aggregated context vector encoding the whole dialogue history.</p>
<p>The <strong>state generator</strong> also uses GRU to predict the value for each(domain, slot) pair. Generator employ a soft-gated pointer-generator copying to combine a <strong>distribution over the vocabulary</strong> and a <strong>distribution over the dialogue history</strong> into a single output distribution.</p>
<p>Finally, the <strong>slot gate</strong> is a simple classifier  that  maps  a  context  vector taken from the encoder hidden states to a probability  distribution  over three classes: <em>ptr</em>, <em>none</em>,  and <em>dontcare</em>.</p>
</div>
<div class="section" id="data-preprocessing">
<h2>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permalink to this headline">¶</a></h2>
<p>First, we need to download the <a class="reference external" href="https://www.repository.cam.ac.uk/bitstream/handle/1810/294507/MULTIWOZ2.1.zip?sequence=1&amp;isAllowed=y">MULTIWOZ2.1.zip</a> file from the <a class="reference external" href="https://www.repository.cam.ac.uk/handle/1810/294507">MultiWOZ</a> project website.</p>
<p>Next, we need to preprocess and reformat the dataset, what will result in division of data into three splits:</p>
<blockquote>
<div><ul class="simple">
<li><p>traininig split (8242 dialogs in the <code class="docutils literal notranslate"><span class="pre">train_dials.json</span></code> file)</p></li>
<li><p>validation split (1000 dialogs in the <code class="docutils literal notranslate"><span class="pre">val_dials.json</span></code> file)</p></li>
<li><p>test split (999 dialogs in the <code class="docutils literal notranslate"><span class="pre">test_dials.json</span></code> file)</p></li>
</ul>
</div></blockquote>
<p>In order to preprocess the MultiWOZ dataset you can use the provided <a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/dialogue_state_tracking/multiwoz/process_multiwoz.py">process_multiwoz</a> script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/nlp/dialogue_state_tracking/multiwoz
python process_multiwoz.py
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default, the script assumes that you will copy data from the unpacked archive into the <code class="docutils literal notranslate"><span class="pre">~/data/state_tracking/MULTIWOZ2.1/MULTIWOZ2.1/</span></code> folder and will store results in the <code class="docutils literal notranslate"><span class="pre">~/data/state_tracking/multiwoz2.1</span></code> folder. Both those can be overriden by passing the command line <code class="docutils literal notranslate"><span class="pre">source_data_dir</span></code> and <code class="docutils literal notranslate"><span class="pre">target_data_dir</span></code> arguments respectively.</p>
</div>
</div>
<div class="section" id="building-the-nemo-graph">
<h2>Building the NeMo Graph<a class="headerlink" href="#building-the-nemo-graph" title="Permalink to this headline">¶</a></h2>
<p>The NeMo training graph consists of the following six modules:</p>
<blockquote>
<div><ul class="simple">
<li><p>data_layer (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collection.nlp.nm.data_layers.MultiWOZDataLayer</span></code>)</p></li>
<li><p>encoder (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.backends.pytorch.common.EncoderRNN</span></code>)</p></li>
<li><p>decoder (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collection.nlp.nm.trainables.TRADEGenerator</span></code>)</p></li>
<li><p>gate_loss_fn (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collection.nlp.nm.losses.CrossEntropyLoss3D</span></code>)</p></li>
<li><p>ptr_loss_fn (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collection.nlp.nm.losses.TRADEMaskedCrossEntropy</span></code>)</p></li>
<li><p>total_loss_fn (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collection.nlp.nm.losses.LossAggregatorNM</span></code>)</p></li>
</ul>
</div></blockquote>
<p>The TRADE model is actually composed of two Neural Modules: encoder and decoder.</p>
</div>
<div class="section" id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h2>
<p>In order to train an instance of the TRADE model on the MultiWOZ 2.1 dataset simply run the ‘dialogue_state_tracking_trade’ script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/nlp/dialogue_state_tracking
python dialogue_state_tracking_trade.py
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Analogically, the script reads that the <code class="docutils literal notranslate"><span class="pre">~/data/state_tracking/multiwoz2.1</span></code> folder by default.
This path can be overriden by passing the command line <code class="docutils literal notranslate"><span class="pre">data_dir</span></code>.</p>
</div>
</div>
<div class="section" id="metrics-and-results">
<h2>Metrics and Results<a class="headerlink" href="#metrics-and-results" title="Permalink to this headline">¶</a></h2>
<p>In the following table we compare the results achieved by our TRADE model implementation with the results achieved in the original paper <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id8">[NLP-DST4]</a>. Additionally, as the authors were relying on the MultiWOZ 2.0
dataset, the table includes also results achieved by TRADE model on the MultiWOZ 2.1 dataset reported in the
<a class="bibtex reference internal" href="#nlp-dst-eric2019multiwoz" id="id9">[NLP-DST2]</a> paper.
Following <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id10">[NLP-DST4]</a>, we used two main metrics to evaluate the model performance:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Joint Goal Accuracy</strong> compares the predicted dialogue states to the ground truth at each dialogue turn, and the
output is considered correct if and only if <strong>all the predicted values exactly match</strong> the ground truth values.</p></li>
<li><p><strong>Slot Accuracy</strong> independently compares each (domain, slot, value) triplet to its ground truth label.</p></li>
</ul>
</div></blockquote>
<table class="docutils align-default">
<colgroup>
<col style="width: 53%" />
<col style="width: 12%" />
<col style="width: 12%" />
<col style="width: 12%" />
<col style="width: 12%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>TRADE implementation</p></th>
<th class="head" colspan="2"><p>MultiWOZ 2.0</p></th>
<th class="head" colspan="2"><p>MultiWOZ 2.1</p></th>
</tr>
<tr class="row-even"><th class="head"></th>
<th class="head"><p>Joint</p></th>
<th class="head"><p>Slot</p></th>
<th class="head"><p>Joint</p></th>
<th class="head"><p>Slot</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd"><td><p><a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id11">[NLP-DST4]</a></p></td>
<td><p>48.62%</p></td>
<td><p>96.92%</p></td>
<td><p>–</p></td>
<td><p>–</p></td>
</tr>
<tr class="row-even"><td><p><a class="bibtex reference internal" href="#nlp-dst-eric2019multiwoz" id="id12">[NLP-DST2]</a></p></td>
<td><p>48.60%</p></td>
<td><p>–</p></td>
<td><p>45.60%</p></td>
<td><p>–</p></td>
</tr>
<tr class="row-odd"><td><p>NeMo (this tutorial)</p></td>
<td><p>–</p></td>
<td><p>–</p></td>
<td><p>42.03%</p></td>
<td><p>96.21%</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>During training the TRADE model uses an additional supervisory signal, enforcing the Slot Gate to properly classify context vector. The <a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/dialogue_state_tracking/multiwoz/process_multiwoz.py">process_multiwoz</a> script extracts that additional information from the dataset,
and the <a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/dialogue_state_tracking/dialogue_state_tracking_trade.py">dialogue_state_tracking_trade</a> script report the <strong>Gating Accuracy</strong> as well.</p>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-nlp/dialog_state_tracking-0"><dl class="citation">
<dt class="bibtex label" id="nlp-dst-budzianowski2018multiwoz"><span class="brackets">NLP-DST1</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id5">2</a>)</span></dt>
<dd><p>Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Inigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gašić. Multiwoz-a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling. <em>arXiv preprint arXiv:1810.00278</em>, 2018.</p>
</dd>
<dt class="bibtex label" id="nlp-dst-eric2019multiwoz"><span class="brackets">NLP-DST2</span><span class="fn-backref">(<a href="#id6">1</a>,<a href="#id9">2</a>,<a href="#id12">3</a>)</span></dt>
<dd><p>Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal, Shuyag Gao, and Dilek Hakkani-Tur. Multiwoz 2.1: multi-domain dialogue state corrections and state tracking baselines. <em>arXiv preprint arXiv:1907.01669</em>, 2019.</p>
</dd>
<dt class="bibtex label" id="nlp-dst-henderson2015machine"><span class="brackets"><a class="fn-backref" href="#id1">NLP-DST3</a></span></dt>
<dd><p>Matthew Henderson. Machine learning for dialog state tracking: a review. <em>research.google</em>, 2015.</p>
</dd>
<dt class="bibtex label" id="nlp-dst-wu2019transferable"><span class="brackets">NLP-DST4</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id4">2</a>,<a href="#id7">3</a>,<a href="#id8">4</a>,<a href="#id10">5</a>,<a href="#id11">6</a>)</span></dt>
<dd><p>Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard Socher, and Pascale Fung. Transferable multi-domain state generator for task-oriented dialogue systems. <em>arXiv preprint arXiv:1905.08743</em>, 2019.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ner.html" class="btn btn-neutral float-right" title="Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="transformer_language_model.html" class="btn btn-neutral float-left" title="Transformer Language Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2019, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>